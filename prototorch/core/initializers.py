"""ProtoTorch code initializers"""

from abc import ABC, abstractmethod
from collections.abc import Iterable
from typing import Union

import torch

from ..utils import parse_data_arg, parse_distribution


# Components
class AbstractComponentsInitializer(ABC):
    """Abstract class for all components initializers."""
    ...


class ShapeAwareCompInitializer(AbstractComponentsInitializer):
    """Abstract class for all dimension-aware components initializers."""
    def __init__(self, shape: Union[Iterable, int]):
        if isinstance(shape, Iterable):
            self.component_shape = tuple(shape)
        else:
            self.component_shape = (shape, )

    @abstractmethod
    def generate(self, num_components: int):
        ...


class DataAwareCompInitializer(AbstractComponentsInitializer):
    """Abstract class for all data-aware components initializers.

    Components generated by data-aware components initializers inherit the shape
    of the provided data.

    """
    def __init__(self,
                 data,
                 noise: float = 0.0,
                 transform: callable = torch.nn.Identity()):
        self.data = data
        self.noise = noise
        self.transform = transform

    def generate_end_hook(self, samples):
        drift = torch.rand_like(samples) * self.noise
        components = self.transform(samples + drift)
        return components

    @abstractmethod
    def generate(self, num_components: int):
        ...
        return self.generate_end_hook(...)

    def __del__(self):
        del self.data


class ClassAwareCompInitializer(AbstractComponentsInitializer):
    """Abstract class for all class-aware components initializers.

    Components generated by class-aware components initializers inherit the shape
    of the provided data.

    """
    def __init__(self,
                 data,
                 noise: float = 0.0,
                 transform: callable = torch.nn.Identity()):
        self.data, self.targets = parse_data_arg(data)
        self.noise = noise
        self.transform = transform
        self.clabels = torch.unique(self.targets).int().tolist()
        self.num_classes = len(self.clabels)

    @property
    @abstractmethod
    def subinit_type(self) -> DataAwareCompInitializer:
        ...

    def generate(self, distribution: Union[dict, list, tuple]):
        distribution = parse_distribution(distribution)
        components = torch.tensor([])
        for k, v in distribution.items():
            stratified_data = self.data[self.targets == k]
            initializer = self.subinit_type(
                stratified_data,
                noise=self.noise,
                transform=self.transform,
            )
            samples = initializer.generate(num_components=v)
            components = torch.cat([components, samples])
        return components

    def __del__(self):
        del self.data
        del self.targets


class LiteralCompInitializer(DataAwareCompInitializer):
    """'Generate' the provided components.

    Use this to 'generate' pre-initialized components from elsewhere.

    """
    def generate(self, num_components: int):
        """Ignore `num_components` and simply return transformed `self.data`."""
        components = self.transform(self.data)
        return components


class ZerosCompInitializer(ShapeAwareCompInitializer):
    """Generate zeros corresponding to the components shape."""
    def generate(self, num_components: int):
        components = torch.zeros((num_components, ) + self.component_shape)
        return components


class OnesCompInitializer(ShapeAwareCompInitializer):
    """Generate ones corresponding to the components shape."""
    def generate(self, num_components: int):
        components = torch.ones((num_components, ) + self.component_shape)
        return components


class FillValueCompInitializer(OnesCompInitializer):
    """Generate components with the provided `fill_value`."""
    def __init__(self, shape, fill_value: float = 1.0):
        super().__init__(shape)
        self.fill_value = fill_value

    def generate(self, num_components: int):
        ones = super().generate(num_components)
        components = ones.fill_(self.fill_value)
        return components


class UniformCompInitializer(OnesCompInitializer):
    """Generate components by sampling from a continuous uniform distribution."""
    def __init__(self, shape, minimum=0.0, maximum=1.0, scale=1.0):
        super().__init__(shape)
        self.minimum = minimum
        self.maximum = maximum
        self.scale = scale

    def generate(self, num_components: int):
        ones = super().generate(num_components)
        components = self.scale * ones.uniform_(self.minimum, self.maximum)
        return components


class RandomNormalCompInitializer(OnesCompInitializer):
    """Generate components by sampling from a standard normal distribution."""
    def __init__(self, shape, shift=0.0, scale=1.0):
        super().__init__(shape)
        self.shift = shift
        self.scale = scale

    def generate(self, num_components: int):
        ones = super().generate(num_components)
        components = self.scale * (torch.randn_like(ones) + self.shift)
        return components


class SelectionCompInitializer(DataAwareCompInitializer):
    """Generate components by uniformly sampling from the provided data."""
    def generate(self, num_components: int):
        indices = torch.LongTensor(num_components).random_(0, len(self.data))
        samples = self.data[indices]
        components = self.generate_end_hook(samples)
        return components


class MeanCompInitializer(DataAwareCompInitializer):
    """Generate components by computing the mean of the provided data."""
    def generate(self, num_components: int):
        mean = torch.mean(self.data, dim=0)
        repeat_dim = [num_components] + [1] * len(mean.shape)
        samples = mean.repeat(repeat_dim)
        components = self.generate_end_hook(samples)
        return components


class StratifiedSelectionCompInitializer(ClassAwareCompInitializer):
    """Generate components using stratified sampling from the provided data."""
    @property
    def subinit_type(self):
        return SelectionCompInitializer


class StratifiedMeanCompInitializer(ClassAwareCompInitializer):
    """Generate components at stratified means of the provided data."""
    @property
    def subinit_type(self):
        return MeanCompInitializer


# Labels
class AbstractLabelsInitializer(ABC):
    """Abstract class for all labels initializers."""
    @abstractmethod
    def generate(self, distribution: Union[dict, list, tuple]):
        ...


class LabelsInitializer(AbstractLabelsInitializer):
    """Generate labels from `distribution`."""
    def generate(self, distribution: Union[dict, list, tuple]):
        distribution = parse_distribution(distribution)
        labels = []
        for k, v in distribution.items():
            labels.extend([k] * v)
        labels = torch.LongTensor(labels)
        return labels


class OneHotLabelsInitializer(LabelsInitializer):
    """Generate one-hot-encoded labels from `distribution`."""
    def generate(self, distribution: Union[dict, list, tuple]):
        distribution = parse_distribution(distribution)
        num_classes = len(distribution.keys())
        # this breaks if class labels are not [0,...,nclasses]
        labels = torch.eye(num_classes)[super().generate(distribution)]
        return labels


# Reasonings
class AbstractReasoningsInitializer(ABC):
    """Abstract class for all reasonings initializers."""
    def __init__(self, components_first=True):
        self.components_first = components_first

    def compute_shape(self, distribution):
        distribution = parse_distribution(distribution)
        num_components = sum(distribution.values())
        num_classes = len(distribution.keys())
        return (num_components, num_classes, 2)

    def generate_end_hook(self, reasonings):
        if not self.components_first:
            reasonings = reasonings.permute(2, 1, 0)
        return reasonings

    @abstractmethod
    def generate(self, distribution: Union[dict, list, tuple]):
        ...
        return generate_end_hook(...)


class ZerosReasoningsInitializer(AbstractReasoningsInitializer):
    """Reasonings are all initialized with zeros."""
    def generate(self, distribution: Union[dict, list, tuple]):
        shape = self.compute_shape(distribution)
        reasonings = torch.zeros(*shape)
        reasonings = self.generate_end_hook(reasonings)
        return reasonings


class OnesReasoningsInitializer(AbstractReasoningsInitializer):
    """Reasonings are all initialized with ones."""
    def generate(self, distribution: Union[dict, list, tuple]):
        shape = self.compute_shape(distribution)
        reasonings = torch.ones(*shape)
        reasonings = self.generate_end_hook(reasonings)
        return reasonings


class RandomReasoningsInitializer(AbstractReasoningsInitializer):
    """Reasonings are randomly initialized."""
    def __init__(self, minimum=0.4, maximum=0.6, **kwargs):
        super().__init__(**kwargs)
        self.minimum = minimum
        self.maximum = maximum

    def generate(self, distribution: Union[dict, list, tuple]):
        shape = self.compute_shape(distribution)
        reasonings = torch.ones(*shape).uniform_(self.minimum, self.maximum)
        reasonings = self.generate_end_hook(reasonings)
        return reasonings


class PurePositiveReasoningsInitializer(AbstractReasoningsInitializer):
    """Each component reasons positively for exactly one class."""
    def generate(self, distribution: Union[dict, list, tuple]):
        num_components, num_classes, _ = self.compute_shape(distribution)
        A = OneHotLabelsInitializer().generate(distribution)
        B = torch.zeros(num_components, num_classes)
        reasonings = torch.stack([A, B]).permute(2, 1, 0)
        reasonings = self.generate_end_hook(reasonings)
        return reasonings


# Aliases - Components
ZCI = ZerosCompInitializer
OCI = OnesCompInitializer
FVCI = FillValueCompInitializer
LCI = LiteralCompInitializer
UCI = UniformCompInitializer
RNCI = RandomNormalCompInitializer
SCI = SelectionCompInitializer
MCI = MeanCompInitializer
SSCI = StratifiedSelectionCompInitializer
SMCI = StratifiedMeanCompInitializer

# Aliases - Labels
LI = LabelsInitializer
OHLI = OneHotLabelsInitializer

# Aliases - Reasonings
ZRI = ZerosReasoningsInitializer
ORI = OnesReasoningsInitializer
RRI = RandomReasoningsInitializer
PPRI = PurePositiveReasoningsInitializer
